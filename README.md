# ğŸ“Š PhonePe Pulse Data Pipeline with MySQL

This project is designed to extract JSON data from PhonePe Pulse data repository and insert it into a structured **MySQL** database. It uses **Python**, **Pandas**, and **MySQL Connector** to perform **ETL (Extract, Transform, Load)** operations across multiple datasets such as **aggregated transactions**, **user data**, **insurance**, **map-based metrics**, and **top district-wise records**.
## ğŸ—ï¸ Project Structure

```bash
project-root/
â”‚
â”œâ”€â”€ pulse/
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ aggregated/
â”‚       â”œâ”€â”€ map/
â”‚       â””â”€â”€ top/
â”œâ”€â”€ main.py  â† Your current script
â””â”€â”€ README.md
```

## ğŸ”§ Requirements

* Python 3.7+
* MySQL Server
* Required Python libraries:

  ```bash
  pip install pandas mysql-connector-python
  ```

---

## âš™ï¸ Setup Instructions

### ğŸ”Œ Step 1: Configure MySQL Connection

In your script:

```python
connection = mysql.connector.connect(
    host='localhost',
    user='root',
    password='root',
    database='phonepay'
)
```

Ensure the database `phonepay` exists before running the script:

```sql
CREATE DATABASE phonepay;
```

---

## ğŸ“ Dataset Modules

### 1. Aggregated Data

#### âœ… `aggregated/transaction`

* Transaction type
* Count
* Amount

#### âœ… `aggregated/user`

* Brand-wise device usage
* Registered users & app opens

#### âœ… `aggregated/insurance`

* Insurance transaction count and amount

---

### 2. Map-Based Data

#### âœ… `map/insurance`

* State-wise insurance data with coordinates

#### âœ… `map/transaction`

* District-level transaction count and amount

#### âœ… `map/user`

* District-level user registrations and app opens

---

### 3. Top Data

#### âœ… `top/insurance`

* Top districts by insurance metrics

---

## ğŸ§  Code Functionality

### ğŸ” Extract Function

Reads nested directory data using:

```python
def extract_transaction_data(path):
    ...
```

### ğŸ§¾ Dataframe to SQL

Converts Pandas DataFrame to tuple list:

```python
def get_list_values(values):
    return [tuple(x) for x in values.to_numpy()]
```

### ğŸ“¥ SQL Table Creation & Insertion

Each dataset includes:

* Table creation with primary keys
* JSON parsing
* Dataframe creation
* `INSERT IGNORE` to prevent duplication

---

## ğŸ How to Run

1. Update all file paths according to your system
2. Ensure MySQL server is running
3. Run the script:

   ```bash
   python main.py
   ```

---

## ğŸ” Primary Keys & Integrity

Each table uses a **composite primary key** for unique entries (e.g., `state + year + quarter + type`) to maintain data integrity and prevent duplicates.

---

## ğŸ“Œ Notes

* You can use `INSERT IGNORE` for idempotent insertions
* Each `.json` file is parsed only if it contains valid data
* Percentages are formatted as string values with `%`

---
## ğŸ“œ License
This project is for educational use. Attribution required if reused in public platforms.
---
